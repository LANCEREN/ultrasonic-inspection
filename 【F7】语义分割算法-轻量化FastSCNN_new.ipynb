{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义分割算法-轻量化Fast-SCNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进入MMSegmentation主目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('mmsegmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\chaosheng\\\\output\\\\MMSegmentation_Tutorials-20230816\\\\mmsegmentation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推荐使用的轻量化语义分割模型\n",
    "\n",
    "Fast-SCNN DDRNet PIDNet STDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wwnj9tRzqX_A"
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('configs/fastscnn/fast_scnn_8xb4-160k_cityscapes-512x1024.py')\n",
    "dataset_cfg = Config.fromfile('./configs/_base_/datasets/LSR16F656_pipeline.py')\n",
    "cfg.merge_from_dict(dataset_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别个数\n",
    "NUM_CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "6195217b-187f-4675-994b-ba90d8bb3078"
   },
   "outputs": [],
   "source": [
    "cfg.norm_cfg = dict(type='BN', requires_grad=True) # 只使用GPU时，BN取代SyncBN\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head[0].norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head[1].norm_cfg = cfg.norm_cfg\n",
    "\n",
    "# 模型 decode/auxiliary 输出头，指定为类别个数\n",
    "cfg.model.decode_head.num_classes = NUM_CLASS\n",
    "cfg.model.auxiliary_head[0]['num_classes'] = NUM_CLASS\n",
    "cfg.model.auxiliary_head[1]['num_classes'] = NUM_CLASS\n",
    "\n",
    "cfg.train_dataloader.batch_size = 4\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# 结果保存目录\n",
    "cfg.work_dir = './work_dirs/LSR16F656-FastSCNN'\n",
    "\n",
    "cfg.train_cfg.max_iters = 30000 # 训练迭代次数\n",
    "cfg.train_cfg.val_interval = 500 # 评估模型间隔\n",
    "cfg.default_hooks.logger.interval = 100 # 日志记录间隔\n",
    "cfg.default_hooks.checkpoint.interval = 2500 # 模型权重保存间隔\n",
    "cfg.default_hooks.checkpoint.max_keep_ckpts = 2 # 最多保留几个模型权重\n",
    "cfg.default_hooks.checkpoint.save_best = 'mIoU' # 保留指标最高的模型权重\n",
    "\n",
    "# 随机数种子\n",
    "cfg['randomness'] = dict(seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看完整config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        1024,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'LSR16F656/'\n",
      "dataset_type = 'LSR16F656'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        by_epoch=False,\n",
      "        interval=2500,\n",
      "        max_keep_ckpts=2,\n",
      "        save_best='mIoU',\n",
      "        type='CheckpointHook'),\n",
      "    logger=dict(interval=100, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "load_from = None\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    auxiliary_head=[\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=32,\n",
      "            concat_input=False,\n",
      "            in_channels=128,\n",
      "            in_index=-2,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=3,\n",
      "            num_convs=1,\n",
      "            type='FCNHead'),\n",
      "        dict(\n",
      "            align_corners=False,\n",
      "            channels=32,\n",
      "            concat_input=False,\n",
      "            in_channels=64,\n",
      "            in_index=-3,\n",
      "            loss_decode=dict(\n",
      "                loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "            norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "            num_classes=3,\n",
      "            num_convs=1,\n",
      "            type='FCNHead'),\n",
      "    ],\n",
      "    backbone=dict(\n",
      "        align_corners=False,\n",
      "        downsample_dw_channels=(\n",
      "            32,\n",
      "            48,\n",
      "        ),\n",
      "        fusion_out_channels=128,\n",
      "        global_block_channels=(\n",
      "            64,\n",
      "            96,\n",
      "            128,\n",
      "        ),\n",
      "        global_block_strides=(\n",
      "            2,\n",
      "            2,\n",
      "            1,\n",
      "        ),\n",
      "        global_in_channels=64,\n",
      "        global_out_channels=128,\n",
      "        higher_in_channels=64,\n",
      "        lower_in_channels=128,\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        out_indices=(\n",
      "            0,\n",
      "            1,\n",
      "            2,\n",
      "        ),\n",
      "        type='FastSCNN'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            1024,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=128,\n",
      "        concat_input=False,\n",
      "        in_channels=128,\n",
      "        in_index=-1,\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1, type='CrossEntropyLoss', use_sigmoid=True),\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        num_classes=3,\n",
      "        type='DepthwiseSeparableFCNHead'),\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "norm_cfg = dict(requires_grad=True, type='BN')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=None,\n",
      "    optimizer=dict(lr=0.12, momentum=0.9, type='SGD', weight_decay=4e-05),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.12, momentum=0.9, type='SGD', weight_decay=4e-05)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0001,\n",
      "        power=0.9,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "randomness = dict(seed=0)\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='LSR16F656/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LSR16F656'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        1024,\n",
      "    ), type='Resize'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(max_iters=30000, type='IterBasedTrainLoop', val_interval=500)\n",
      "train_dataloader = dict(\n",
      "    batch_size=4,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='img_dir/train', seg_map_path='ann_dir/train'),\n",
      "        data_root='LSR16F656/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    1024,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LSR16F656'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            1024,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(file_client_args=dict(backend='disk'), type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),\n",
      "        data_root='LSR16F656/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                1024,\n",
      "            ), type='Resize'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        type='LSR16F656'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "        'mDice',\n",
      "        'mFscore',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = './work_dirs/LSR16F656-FastSCNN'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存最终的config配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dump('LSR16F656-Configs/LSR16F656_FastSCNN_20240104.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "20d4b83e0c8b3730b580c42434163d64f4b735d580303a8fade7c849d4d29eba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
